{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment8_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKNaurvjTShp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grading = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y7pkknmTW8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MC3gFWWTYNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_questions():\n",
        "  \"\"\"\n",
        "  Task 1a)\n",
        "\n",
        "  Load the questions and their classes.\n",
        "\n",
        "  Complete the following steps:\n",
        "    - load the file \"train_5500.label.txt\" with \"ISO-8859-1\" encoding\n",
        "    - read the lines of the file\n",
        "    - consider only the lines that start with \"LOC:city\" or \"HUM:ind\"\n",
        "    - create a list in the following format:\n",
        "      [ (text, class), ... ]\n",
        "    - \"text\" is the content of the line AFTER the label\n",
        "       LOC:city What is the name of the city that Maurizio Pellegrin lives in ?\n",
        "      For this line the content would be: \"What is the name of the city that Maurizio Pellegrin lives in ?\"\n",
        "    - class is based on the label: \"CITY\" for \"LOC:city\" and \"HUMAN\" for \"HUM:ind\"\n",
        "      For the example above this would be \"CITY\"\n",
        "    - keep only the first 128 lines with class \"HUMAN\" (labelled as \"HUM:ind\")\n",
        "    - keep all samples for \"CITY\"\n",
        "    - return the list in the format described above\n",
        "  \n",
        "  :return: A list of questions in the format [ (text, class), ... ]\n",
        "  \"\"\"\n",
        "  texts = []\n",
        "  ### YOUR CODE HERE ###\n",
        "  return texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YKQ4hcGO0_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "    from collections import Counter\n",
        "    texts = load_questions()\n",
        "    count = Counter(x[1] for x in texts)\n",
        "    print(count)\n",
        "    # Counter({'CITY': 129, 'HUMAN': 128})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Ohb-E6Tgm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dataframe_q(texts):\n",
        "  \"\"\"\n",
        "  Task 1b)\n",
        "\n",
        "  Process the texts and create a DataFrame you can use for training a classifier.\n",
        "\n",
        "  Complete the following steps:\n",
        "    - load the spacy model \"en_core_web_sm\"\n",
        "    - for each text, create a spacy doc object\n",
        "    - for each token in this doc object, do:\n",
        "      - if the token begins an entity, keep the entity type\n",
        "      - elif the token is outside an entity, and not a stopword, keep token.text\n",
        "      - if the token is a stopword, continue\n",
        "      - keep token.text\n",
        "        (if the token is outside an entity then this means you keep token.text twice)\n",
        "      - you can find everything you need here: https://spacy.io/api/token\n",
        "      - create a dictionary for the current document in this format:\n",
        "        {\n",
        "          \"text\": list of the tokens joined with whitespace (use \" \".join(tokens)),\n",
        "          \"class\": the class of the text,\n",
        "        }\n",
        "      - store this dictionary, for each document, in a list\n",
        "      - create a new dataframe where each row is represented by one of the\n",
        "       document dictionaries\n",
        "      - return this dataframe\n",
        "  \n",
        "  :param texts: A list of texts as returned by the \"load_questions()\" method.\n",
        "  :return: A DataFrame with columns \"text\", \"class\", where \"text\"\n",
        "    contains the preprocessed text from the list of texts, \"class\" the label of \n",
        "    the text.\n",
        "  \"\"\"\n",
        "  rows = []\n",
        "  ### YOUR CODE HERE ###\n",
        "  df = pd.DataFrame(rows)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XENeY7BDSj9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "    df = build_dataframe_q(texts)\n",
        "    print(df.iloc[10])\n",
        "    # text        city city oldest oldest relationship relations...\n",
        "    # class                                                    CITY\n",
        "    # Name: 10, dtype: object\n",
        "    print(\"----\")\n",
        "    print(df.iloc[100])\n",
        "    # text        FAC McCarren Airport located located city city...\n",
        "    # class                                                    CITY\n",
        "    # Name: 100, dtype: object\n",
        "    print(\"----\")\n",
        "    print(df.iloc[123])\n",
        "    # text        graced graced airwaves airwaves pearls pearls ...\n",
        "    # class                                                   HUMAN\n",
        "    # Name: 123, dtype: object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJaTDptlTmsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_test_set(df, train_size, test_size, random_state=42):\n",
        "  \"\"\"\n",
        "  Task 1c)\n",
        "\n",
        "  Split a DataFrame into training and test set.\n",
        "  Use a method from scikit-learn to accomplish this.\n",
        "\n",
        "  !!! You need to import this scikit-learn method! !!!\n",
        "\n",
        "  Specify the train_size, test_size and random_state of this scikit-learn method\n",
        "  to use the values passed into this function.\n",
        "\n",
        "  Return in the following format (four return values):\n",
        "    training_data, test_data, training_labels, test_labels\n",
        "\n",
        "  :param df: The DataFrame as created by \"build_dataframe_q()\"\n",
        "  :param train_size: The size of the training set.\n",
        "  :param test_size: The size of the test set. Must add up to 1 with train_size.\n",
        "    Example: train_size=0.3 and test_size=0.7 would be a 30:70 train:test split.\n",
        "  :param random_state: Optional. Default: 42. The random state to ensure\n",
        "    consistency across different function calls.\n",
        "  :return: X_train, X_test, y_train, y_test - in other words: The training \n",
        "    samples, the test samples, the training sample labels, the test sample\n",
        "    labels.\n",
        "  \"\"\"\n",
        "  ### YOUR CODE HERE ###\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BLuuqkpSm-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "    X_train, X_test, y_train, y_test = create_train_test_set(df, 0.6, 0.4)\n",
        "    print(len(X_train))\n",
        "    print(len(X_test))\n",
        "    print(len(y_train))\n",
        "    print(len(y_test))\n",
        "    # 154\n",
        "    # 103\n",
        "    # 154\n",
        "    # 103"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUyOMB63TubO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gridsearch(clf, parameters, X, y):\n",
        "  \"\"\"\n",
        "  Task 1d)\n",
        "\n",
        "  Perform a gridsearch for a given classifier, data and parameters.\n",
        "  Print the best parameters and also return them.\n",
        "\n",
        "  The parameters of this function are the same ones you can pass directly into\n",
        "  the scikit-learn GridSearchCV: \n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "  :param clf: A classifier object.\n",
        "  :param parameters: The parameters to be tried out for the gridsearch.\n",
        "  :param X: The (training) samples used to optimize for.\n",
        "  :param y: The (training) sample labels used to optimize for.\n",
        "  :return: The best parameters, as found by the gridsearch, as a dictionary.\n",
        "  \"\"\"\n",
        "  ### YOUR CODE HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cYSxSK1TyTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_classifier(true_labels, predictions):\n",
        "  \"\"\"\n",
        "  Task 1e)\n",
        "\n",
        "  true_labels = The class labels of your test set.\n",
        "  predictions = The predicted labels, predictions made by your classifier.\n",
        "\n",
        "  Evaluate how good the predictions of a classifier are.\n",
        "  \"true_labels\" are the correct class labels, \"predictions\" is what the\n",
        "  classifier predicted.\n",
        "\n",
        "  Calculate the following:\n",
        "    - accuracy\n",
        "    - precision (weighted)\n",
        "    - recall (weighted)\n",
        "    - f1 (weighted)\n",
        "  Return in the format (accuracy, precision, recall, f1)\n",
        "\n",
        "  :param true_labels: The correct labels for the data.\n",
        "  :param predictions: The labels as predicted by the classifier.\n",
        "  :return: accuracy, precision, recall, f1\n",
        "  \"\"\"\n",
        "  ### YOUR CODE HERE ###\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYMo-RRGOLkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(df, clf, do_gridsearch=False, parameters=None):\n",
        "  \"\"\"\n",
        "  Task 1f)\n",
        "\n",
        "  Train and evaluate a classifier.\n",
        "\n",
        "    - Split the data (df) into training and test set, using your\n",
        "      \"create_train_test_set\" method.\n",
        "      Use a 60:40 training:test split.\n",
        "    - create a vectorizer object. You can find vectorizers here:\n",
        "      https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
        "      Pick one that you think is suitable. If you are unsure, pick any one of \n",
        "      them and evaluate your classifier. Then replace the vectorizer (change\n",
        "      your code to use a different vectorizer and run the cell again) \n",
        "      and see how the results change.\n",
        "      The task should be solvable with any of the vectorizers, but some of them\n",
        "      are better suited for this task than others.\n",
        "    - transform your training data using the .fit_transform() method of\n",
        "      the vectorizer (read the scikit-learn documentation of your vectorizer\n",
        "      to see how to call this method)\n",
        "    - use the .fit method of the classifier to train your classifier\n",
        "      Example here:\n",
        "      https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier.fit\n",
        "    - get the predictions for your test data using clf.predict()\n",
        "      HINT: There is something you need to do with your test data beforehand.\n",
        "            You had to do the same thing with your training data before you could\n",
        "            use the .fit method..\n",
        "    - calculate accuracy, precision, recall and f1-measure of your classifier\n",
        "      based on the predictions of your test set and the vectorizer\n",
        "      Use your \"evaluate_classifier\" method for this.\n",
        "      Return these values in the format (accuracy, precision, recall, f1, vectorizer)\n",
        "  \n",
        "  :param df: The DataFrame as created by \"build_dataframe_q\".\n",
        "  :param clf: A scikit-learn classifier.\n",
        "  :param do_gridsearch: Optional. Default: False. Whether to perform a gridsearch.\n",
        "  :param paramaters: Optional. Default: None. Only used if do_gridsearch=True.\n",
        "    The parameters to use in the gridsearch.\n",
        "  :return: accuracy, precision, recall, f1 (all 4 based on the classifier's \n",
        "    performance), vectorizer\n",
        "  \"\"\"\n",
        "  return accuracy, precision, recall, f1, vectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u0NoK_hT94o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_pa(df):\n",
        "  \"\"\"\n",
        "  Task 2a)\n",
        "\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html\n",
        "  Train a PassiveAggressiveClassifier on the provided data.\n",
        "  Accuracy, precision, recall and f1-measure should all be above 96%.\n",
        "\n",
        "  Optimize the classifier parameters so the result of your \"train_classifier\"\n",
        "  fucntion are all above 96%.\n",
        "\n",
        "  HINT: Perform a gridsearch to find optimized parameters to improve your\n",
        "        classifier.\n",
        "  \n",
        "  :return: accuracy, precision, recall, f1, vectorizer\n",
        "  \"\"\"\n",
        "  clf = PassiveAggressiveClassifier(random_state=42)\n",
        "  accuracy, precision, recall, f1, v = train_classifier(df, clf)\n",
        "  print(accuracy, precision, recall, f1)\n",
        "  pred = clf.predict(v.transform([\"Who is Ghandi?\"]))\n",
        "  print(pred)\n",
        "  return accuracy, precision, recall, f1, v\n",
        "\n",
        "if not grading:\n",
        "    q = load_questions()\n",
        "    df = build_dataframe_q(q)\n",
        "    accuracy, precision, recall, f1, v = build_pa(df)\n",
        "    print(accuracy, precision, recall, f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZAkJ4AyUDqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_mnb(df):\n",
        "  \"\"\"\n",
        "  Task 2b)\n",
        "\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html \n",
        "  Train an MultinomialNB classifier on the provided data.\n",
        "  Accuracy, precision, recall and f1-measure should all be above 79%.\n",
        "\n",
        "  Optimize the classifier parameters so the result of your \"train_classifier\"\n",
        "  fucntion are all above 79%.\n",
        "\n",
        "  HINT: Perform a gridsearch to find optimized parameters to improve your\n",
        "        classifier.\n",
        "\n",
        "  :return: accuracy, precision, recall, f1, vectorizer\n",
        "  \"\"\"\n",
        "  clf = MultinomialNB()\n",
        "  accuracy, precision, recall, f1, v = train_classifier(df, clf)\n",
        "  print(accuracy, precision, recall, f1)\n",
        "  pred = clf.predict(v.transform([\"Who is Ghandi?\"]))\n",
        "  print(pred)\n",
        "  return accuracy, precision, recall, f1, v\n",
        "\n",
        "if not grading:\n",
        "    q = load_questions()\n",
        "    df = build_dataframe_q(q)\n",
        "    accuracy, precision, recall, f1, v = build_mnb(df)\n",
        "    print(accuracy, precision, recall, f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QZRCJljUOkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_svc(df):\n",
        "  \"\"\"\n",
        "  Task 2c)\n",
        "\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html  Train an SVC on the provided data.\n",
        "  Accuracy, precision, recall and f1-measure should all be above 96%.\n",
        "\n",
        "  Optimize the classifier parameters so the result of your \"train_classifier\"\n",
        "  fucntion are all above 96%.\n",
        "\n",
        "  HINT: Perform a gridsearch to find optimized parameters to improve your\n",
        "        classifier.\n",
        "\n",
        "  :return: accuracy, precision, recall, f1, vectorizer\n",
        "  \"\"\"\n",
        "  clf = SVC()\n",
        "  accuracy, precision, recall, f1, v = train_classifier(df, clf)\n",
        "  print(accuracy, precision, recall, f1)\n",
        "  pred = clf.predict(v.transform([\"Who is Ghandi?\"]))\n",
        "  print(pred)\n",
        "  return accuracy, precision, recall, f1, v\n",
        "\n",
        "if not grading:\n",
        "    q = load_questions()\n",
        "    df = build_dataframe_q(q)\n",
        "    accuracy, precision, recall, f1, v = build_svc(df)\n",
        "    print(accuracy, precision, recall, f1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}