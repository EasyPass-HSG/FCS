{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment7_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5ACbst-mTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grading = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhe3ehDkYaXF",
        "colab_type": "code",
        "outputId": "9890c2f8-9bcf-4f4f-fc8c-c9e12e380200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if not grading: \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwsaLxhGYpE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avth2IRtYpxL",
        "colab_type": "code",
        "outputId": "a4dd31c4-8750-4652-d8fd-7cb988dee06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "if not grading:\n",
        "  # adjust this if you DON'T use google drive but instead upload the files \n",
        "  # train_df = pd.read_csv(\"a7_train.csv\")\n",
        "  train_file_path = \"/content/drive/My Drive/a7_train.csv\"\n",
        "  train_df = pd.read_csv(train_file_path)\n",
        "\n",
        "  train_df\n",
        "else:\n",
        "  train_df = pd.read_csv(\"a7_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>I'm sure that the folks on the Texas/Louisiana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>The excruciatingly slow pace of this film was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>I had the \"privilege\" of attending a special s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>I know it's a Power-Rangers gimmick and catere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>Lordi was a major hype and revelation in 2007 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>pos</td>\n",
              "      <td>As far as I can recall, Balanchine's alteratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>pos</td>\n",
              "      <td>John Van Druten's \"Bell, Book and Candle\" is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>pos</td>\n",
              "      <td>This was a great romantic comedy! Historically...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>pos</td>\n",
              "      <td>No Strings Attached is one of Carlos Mencia's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>pos</td>\n",
              "      <td>What I liked best in this film is that like th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                               text\n",
              "0       neg  I'm sure that the folks on the Texas/Louisiana...\n",
              "1       neg  The excruciatingly slow pace of this film was ...\n",
              "2       neg  I had the \"privilege\" of attending a special s...\n",
              "3       neg  I know it's a Power-Rangers gimmick and catere...\n",
              "4       neg  Lordi was a major hype and revelation in 2007 ...\n",
              "...     ...                                                ...\n",
              "24995   pos  As far as I can recall, Balanchine's alteratio...\n",
              "24996   pos  John Van Druten's \"Bell, Book and Candle\" is a...\n",
              "24997   pos  This was a great romantic comedy! Historically...\n",
              "24998   pos  No Strings Attached is one of Carlos Mencia's ...\n",
              "24999   pos  What I liked best in this film is that like th...\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTrezgijY5-2",
        "colab_type": "code",
        "outputId": "0c6d6247-9b78-48ab-c1a4-220d5ecdff69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "if not grading:\n",
        "  # adjust this if you DON'T use google drive but instead upload the files \n",
        "  # train_df = pd.read_csv(\"a7_test.csv\")\n",
        "  test_file_path = \"/content/drive/My Drive/a7_test.csv\"\n",
        "  import pandas as pd\n",
        "  test_df = pd.read_csv(test_file_path)\n",
        "  test_df\n",
        "else:\n",
        "  train_df = pd.read_csv(\"a7_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>Plot Synopsis: Los Angeles in the future. Crim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>This movie is something horrible. I was laughi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>This film is strictly for fans of Debbie Reyno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>This is one the worst movie I've seen and cert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>After missing out on this innumerable times on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>pos</td>\n",
              "      <td>Mark Walhberg in a great role, idolises a rock...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>pos</td>\n",
              "      <td>I too saw this movie when it first came out. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>pos</td>\n",
              "      <td>If you haven't seen this yet, you really shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>pos</td>\n",
              "      <td>This film, also known as \"don't look in the ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>pos</td>\n",
              "      <td>My introduction to a lifelong love of Shakespe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                                               text\n",
              "0       neg  Plot Synopsis: Los Angeles in the future. Crim...\n",
              "1       neg  This movie is something horrible. I was laughi...\n",
              "2       neg  This film is strictly for fans of Debbie Reyno...\n",
              "3       neg  This is one the worst movie I've seen and cert...\n",
              "4       neg  After missing out on this innumerable times on...\n",
              "...     ...                                                ...\n",
              "24995   pos  Mark Walhberg in a great role, idolises a rock...\n",
              "24996   pos  I too saw this movie when it first came out. I...\n",
              "24997   pos  If you haven't seen this yet, you really shoul...\n",
              "24998   pos  This film, also known as \"don't look in the ba...\n",
              "24999   pos  My introduction to a lifelong love of Shakespe...\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrRat9noZAvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_priors(df):\n",
        "  \"\"\"\n",
        "  TASK 1a)\n",
        "\n",
        "  Calculates the probability of given classes, based on how often they appear\n",
        "  in a DataFrame.\n",
        "\n",
        "  You can assume that the class values for each row are in a column called\n",
        "  \"class\".\n",
        "\n",
        "  !!! Your function must work for any number of classes, so don't assume that \n",
        "  the number of classes is always exactly 2! !!!\n",
        "  \n",
        "  Return a dictionary mapping the class to its probability.\n",
        "  Example: The class \"apple\" appears in two rows, the class \"banana\" in three.\n",
        "  The probability for the \"apple\" class is 2/5, the probability for banana is \n",
        "  3/5.\n",
        "  You have to return a dictionary:\n",
        "    {\"apple\": 0.4, \"banana\": 0.6}\n",
        "\n",
        "  HINT: You can use .value_counts() to count the values in a column.\n",
        "    You have to select the correct column first.\n",
        "  HINT: You can use .apply to modify values with the use of a function, such as\n",
        "    a lambda function.\n",
        "\n",
        "  :param df: The DataFrame. \n",
        "  :return: A dictionary mapping the class to its probability.\n",
        "  \"\"\"\n",
        "  return {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk6OM3gPZmnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "  priors = calculate_priors(train_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWkmctLrZOr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_class_term_frequency(df, classes):\n",
        "  \"\"\"\n",
        "  TASK 1b)\n",
        "\n",
        "  For each, calculates the frequency of terms appearing in texts of this class.\n",
        "\n",
        "  You are given a DataFrame, containing a column \"class\" and a column \"text\".\n",
        "  You are also given a list \"classes\", containing the possible values for the\n",
        "  \"class\" column.\n",
        "  You can see that each row has an entry for \"text\" and one for \"class\". The \n",
        "  values in the \"text\" column are strings (= actual texts).\n",
        "  Your task is to calculate the frequency (= how often a word appears) for each\n",
        "  of the classes and individually.\n",
        "\n",
        "  Example: \n",
        "    There are two texts with the \"apple\" class. \n",
        "    There are three texts with the \"banana\" class.\n",
        "    The word \"fruit\" appears five times in the texts of the \"apple\" class, and \n",
        "    two times for texts of the \"banana\" class.\n",
        "    The total frequency of the word \"fruit\" is 7. The frequency for the \"apple\"\n",
        "    class is 5. The frequency for the \"banana\" class is 2.\n",
        "\n",
        "  To get the individual terms you can use .split(\" \") (splitting by whitespace).\n",
        "  Convert the terms to lowercase.\n",
        "\n",
        "  HINT: You can iterate over the DataFrame rows with .iterrows():\n",
        "  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html\n",
        "\n",
        "\n",
        "  Store the frequencies in a dictionary.\n",
        "  Return a set containing all the terms and the frequency dictionary.\n",
        "  \n",
        "  \"\"\"\n",
        "  return set(), {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Hn1uHxZsed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "  classes = priors.keys()\n",
        "  terms, freqs_per_class = calculate_class_term_frequency(train_df, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYjtusnMZU0o",
        "colab_type": "text"
      },
      "source": [
        "**Conditional Probabilities (with add-1 smoothing)**: $P(w|c) = \\frac{count(w, c) + 1}{count(c) + |V|}$\n",
        "\n",
        "Example: $P(fruit|apple) = 0.3$\n",
        "\n",
        "$count(w, c)$ = How often word $w$ appears in documents of class $c$.\n",
        "\n",
        "$count(c)$ = How many words appear in documents of class $c$.\n",
        "\n",
        "$|V|$ = How many different words exist in the dataset.\n",
        "\n",
        "**Prior**: $P_{prior}(c) = \\frac{N_c}{N}$, where $N$ is the total number of documents and $N_c$ is the number of documents with class $c$\n",
        "\n",
        "**Choosing a class for document $d$**: $argmax_{c \\in C} P(c|d)$ with $P(c|d) = P_{prior}(c) * \\prod_{w \\in d} P(w|c)$\n",
        "\n",
        "You can also refer to the lecture slides where you can find an example calculation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G82uFZKJZWA-",
        "colab_type": "code",
        "outputId": "0350b1a3-7d65-4d04-9048-8f8825892987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "if not grading:\n",
        "  example_dct = {\"fruit\": {\"apple\": 0.3, \"banana\": 0.4}, \"tree\": {\"apple\": 0.5, \"banana\": 0.1}}\n",
        "  print(example_dct[\"fruit\"])  # prints the inner dictionary\n",
        "  # prints the probability of \"fruit\" appearing in a document if the document has the class \"apple\"\n",
        "  print(example_dct[\"fruit\"][\"apple\"])  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'apple': 0.3, 'banana': 0.4}\n",
            "0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtz2IcomZYna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_class_term_probs(terms, freqs_per_class):\n",
        "  \"\"\"\n",
        "  TASK 1c)\n",
        "\n",
        "  Calculates the probability that a term appears in documents of a given class \n",
        "  and returns a nested dictionary containing the probabilities.\n",
        "\n",
        "  Use Laplace (add-1) smoothing.\n",
        "  Return a nested dictionary. The outer dictionary needs map terms to the \n",
        "  inner dictionaries. The inner dictionary maps class labels to probabilities.\n",
        "\n",
        "  -> If the dictionary is accessed with a non-existing key but an existing class\n",
        "  it should return the value 1/|V| ! <--\n",
        "\n",
        "  Example:\n",
        "    dct = {\"fruit\": {\"apple\": 0.3, \"banana\": 0.4}, \"tree\": {\"apple\": 0.5, \"banana\": 0.1}}\n",
        "    foo = dct[\"rock\"][\"apple\"]\n",
        "    foo == 1/2\n",
        "    Two terms exist in total (fruit and tree) so the total vocabulary size is 2.\n",
        "\n",
        "\n",
        "  HINT: Use defaultdict(): https://docs.python.org/3.8/library/collections.html#collections.defaultdict\n",
        "  \"\"\"\n",
        "  return {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLHXVO6TaIfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "  probs = calculate_class_term_probs(terms, freqs_per_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlVMNfrZcQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(text, priors, probs):\n",
        "  \"\"\"\n",
        "  TASK 1d)\n",
        "  This function should predict a class for a given text.\n",
        "  \"text\" will always be a single text (string).\n",
        "  Use the priors you calculated in 1a).\n",
        "  Use the probabilities you calculated in 1c).\n",
        "  Use the Naive Bayes classification to assign the class.\n",
        "  Return the class label as a string.\n",
        "  \"\"\"\n",
        "  return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMUwhG-5ZfG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(test, priors, probs):\n",
        "  \"\"\"\n",
        "  TASK 1e)\n",
        "  Evaluate your classification.\n",
        "\n",
        "  -> You may assume that the only classes are \"pos\" and \"neg\" ! <--\n",
        "\n",
        "  Use the test set for your evaluation.\n",
        "  For each row in the test set, get the actual class from the \"class\" column\n",
        "  and the text from the \"text\" column.\n",
        "  Use your \"classify(text, priors, probs)\" function to get the predicted\n",
        "  class label for each text.\n",
        "\n",
        "  HINT: Count the TP, FP, FN for each of the two classes, for each prediction. \n",
        "\n",
        "  Calculate the following metrics PER CLASS:\n",
        "    - precision\n",
        "    - recall\n",
        "    - f1-measure\n",
        "  Return a list of tuples in the following format:\n",
        "    [(class label, precision, recall, f1-measure), ...]\n",
        "  \"\"\"\n",
        "  return []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FILR7HD_aPKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not grading:\n",
        "  results = evaluate(test_df, priors, probs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}